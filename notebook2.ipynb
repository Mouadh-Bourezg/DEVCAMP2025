{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Complete preprocessing pipeline for demand forecasting data\"\"\"\n",
    "\n",
    "     # 0. Drop old record_id and create new sequential index\n",
    "    if 'record_ID' in df.columns:\n",
    "        df = df.drop(columns=['record_ID'])\n",
    "    df = df.reset_index(drop=True)  # Creates new 0-based index\n",
    "    \n",
    "    # 1. Clean data - remove rows where total_price > base_price\n",
    "    print(f\"Original data shape: {df.shape}\")\n",
    "    df = df[df['total_price'] <= df['base_price']].copy()\n",
    "    print(f\"After removing invalid prices: {df.shape}\")\n",
    "    \n",
    "    # 2. Transform IDs to categorical\n",
    "    df['store_id'] = df['store_id'].astype('category')\n",
    "    df['sku_id'] = df['sku_id'].astype('category')\n",
    "    \n",
    "    # 3. Add discount ratio and drop total_price\n",
    "    df['discount_ratio'] = (df['base_price'] - df['total_price']) / df['base_price']\n",
    "    df = df.drop(columns=['total_price'])\n",
    "    \n",
    "    # 4. Handle datetime ... later\n",
    "\n",
    "    \n",
    "    # 5. Outlier detection and removal\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=df, x='units_sold')\n",
    "    plt.title('Boxplot of Units Sold Before Outlier Removal')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate IQR for units_sold\n",
    "    Q1 = df['units_sold'].quantile(0.25)\n",
    "    Q3 = df['units_sold'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Remove outliers\n",
    "    original_size = len(df)\n",
    "    df = df[(df['units_sold'] >= lower_bound) & (df['units_sold'] <= upper_bound)]\n",
    "    print(f\"Removed {original_size - len(df)} outliers ({((original_size - len(df))/original_size)*100:.2f}% of data)\")\n",
    "    \n",
    "    # 6. Feature scaling\n",
    "    numeric_cols = ['base_price', 'discount_ratio', 'units_sold']\n",
    "    \n",
    "    \n",
    "    # Standard scale other numeric features\n",
    "    feature_scaler = StandardScaler()\n",
    "    df[numeric_cols[:-1]] = feature_scaler.fit_transform(df[numeric_cols[:-1]])\n",
    "    \n",
    "    # Show preprocessing results\n",
    "    print(\"\\nFinal preprocessed data:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_series(df):\n",
    "    # Convert and extract datetime\n",
    "    df['week'] = pd.to_datetime(df['week'])\n",
    "    df['year'] = df['week'].dt.year\n",
    "    df['week_of_year'] = df['week'].dt.isocalendar().week\n",
    "    df['day_of_year'] = df['week'].dt.dayofyear\n",
    "    \n",
    "    # Lagged features\n",
    "    for lag in [1, 2, 4, 12]:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['sku_id', 'store_id'])['units_sold'].shift(lag)\n",
    "    \n",
    "    # Rolling stats\n",
    "    df['rolling_avg_4w'] = df.groupby(['sku_id', 'store_id'])['units_sold'].transform(\n",
    "        lambda x: x.rolling(4, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Drop rows with NaN from lagging\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_devcamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (133980, 8)\n",
      "After removing invalid prices: (130946, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9171 outliers (7.00% of data)\n",
      "\n",
      "Final preprocessed data:\n",
      "         week store_id  sku_id  base_price  is_featured_sku  is_display_sku  \\\n",
      "0  2011-01-17     8091  216418   -0.989567                0               0   \n",
      "1  2011-01-17     9672  223153    0.123547                1               1   \n",
      "2  2011-01-17     9672  223245   -0.137240                0               0   \n",
      "3  2011-01-17     9672  222765    0.168072                0               0   \n",
      "5  2011-01-17     9672  219029    0.931350                0               0   \n",
      "\n",
      "   units_sold  discount_ratio  \n",
      "0          20        0.784159  \n",
      "1         109        1.567048  \n",
      "2          61       -0.460796  \n",
      "3          49       -0.460796  \n",
      "5          39       -0.460796  \n",
      "\n",
      "Missing values:\n",
      "week               0\n",
      "store_id           0\n",
      "sku_id             0\n",
      "base_price         0\n",
      "is_featured_sku    0\n",
      "is_display_sku     0\n",
      "units_sold         0\n",
      "discount_ratio     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>discount_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8091</td>\n",
       "      <td>216418</td>\n",
       "      <td>-0.989567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.784159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9672</td>\n",
       "      <td>223153</td>\n",
       "      <td>0.123547</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>1.567048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9672</td>\n",
       "      <td>223245</td>\n",
       "      <td>-0.137240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.460796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9672</td>\n",
       "      <td>222765</td>\n",
       "      <td>0.168072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.460796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9672</td>\n",
       "      <td>219029</td>\n",
       "      <td>0.931350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.460796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         week store_id  sku_id  base_price  is_featured_sku  is_display_sku  \\\n",
       "0  2011-01-17     8091  216418   -0.989567                0               0   \n",
       "1  2011-01-17     9672  223153    0.123547                1               1   \n",
       "2  2011-01-17     9672  223245   -0.137240                0               0   \n",
       "3  2011-01-17     9672  222765    0.168072                0               0   \n",
       "5  2011-01-17     9672  219029    0.931350                0               0   \n",
       "\n",
       "   units_sold  discount_ratio  \n",
       "0          20        0.784159  \n",
       "1         109        1.567048  \n",
       "2          61       -0.460796  \n",
       "3          49       -0.460796  \n",
       "5          39       -0.460796  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_df = preprocess_data(df)\n",
    "prepro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bking\\AppData\\Local\\Temp\\ipykernel_10112\\3816713201.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby(['sku_id', 'store_id'])['units_sold'].shift(lag)\n",
      "C:\\Users\\bking\\AppData\\Local\\Temp\\ipykernel_10112\\3816713201.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby(['sku_id', 'store_id'])['units_sold'].shift(lag)\n",
      "C:\\Users\\bking\\AppData\\Local\\Temp\\ipykernel_10112\\3816713201.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby(['sku_id', 'store_id'])['units_sold'].shift(lag)\n",
      "C:\\Users\\bking\\AppData\\Local\\Temp\\ipykernel_10112\\3816713201.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby(['sku_id', 'store_id'])['units_sold'].shift(lag)\n",
      "C:\\Users\\bking\\AppData\\Local\\Temp\\ipykernel_10112\\3816713201.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['rolling_avg_4w'] = df.groupby(['sku_id', 'store_id'])['units_sold'].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features after encoding: 116\n",
      "NaN values in final DataFrame: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id_8023</th>\n",
       "      <th>store_id_8058</th>\n",
       "      <th>store_id_8063</th>\n",
       "      <th>store_id_8091</th>\n",
       "      <th>store_id_8094</th>\n",
       "      <th>store_id_8095</th>\n",
       "      <th>store_id_8121</th>\n",
       "      <th>store_id_8218</th>\n",
       "      <th>store_id_8222</th>\n",
       "      <th>store_id_8317</th>\n",
       "      <th>...</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>discount_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>sales_lag_1</th>\n",
       "      <th>sales_lag_2</th>\n",
       "      <th>sales_lag_4</th>\n",
       "      <th>sales_lag_12</th>\n",
       "      <th>rolling_avg_4w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460796</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>73.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>91.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460796</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>30.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460796</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641076</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460796</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>53.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id_8023  store_id_8058  store_id_8063  store_id_8091  store_id_8094  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   store_id_8095  store_id_8121  store_id_8218  store_id_8222  store_id_8317  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   ...  is_display_sku  discount_ratio  year  week_of_year  day_of_year  \\\n",
       "0  ...               0       -0.460796  2011            15          101   \n",
       "1  ...               0       -0.460796  2011            15          101   \n",
       "2  ...               0       -0.460796  2011            15          101   \n",
       "3  ...               1        0.641076  2011            15          101   \n",
       "4  ...               0       -0.460796  2011            15          101   \n",
       "\n",
       "   sales_lag_1  sales_lag_2  sales_lag_4  sales_lag_12  rolling_avg_4w  \n",
       "0         73.0        117.0         80.0          49.0           91.00  \n",
       "1         30.0         77.0         66.0          50.0           55.00  \n",
       "2         15.0         18.0         26.0          21.0           17.75  \n",
       "3         30.0         19.0         33.0          30.0           20.00  \n",
       "4         53.0        100.0         37.0          33.0           66.25  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply time-series preparation\n",
    "final_df = prepare_time_series(prepro_df)\n",
    "\n",
    "# Separate features and target\n",
    "X = final_df.drop(columns=['units_sold', 'week'])\n",
    "y = final_df['units_sold']\n",
    "\n",
    "# One-Hot Encoding for categoricals\n",
    "cat_cols = ['store_id', 'sku_id']\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X[cat_cols])\n",
    "encoded_feature_names = encoder.get_feature_names_out(cat_cols)\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_feature_names)\n",
    "\n",
    "# Reset index for both DataFrames before concatenation\n",
    "numeric_cols = [col for col in X.columns if col not in cat_cols]\n",
    "X_encoded_df = X_encoded_df.reset_index(drop=True)\n",
    "X_numeric = X[numeric_cols].reset_index(drop=True)\n",
    "\n",
    "# Combine with numeric features\n",
    "X_final = pd.concat([X_encoded_df, X_numeric], axis=1)\n",
    "\n",
    "print(f\"Total features after encoding: {X_final.shape[1]}\")\n",
    "print(f\"NaN values in final DataFrame: {X_final.isnull().sum().sum()}\")  # Should be 0\n",
    "\n",
    "X_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced from 116 to 3 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 83.0063231 ,  97.61905657, -32.39263522],\n",
       "       [ 82.46438898,  37.10678264,   3.30839757],\n",
       "       [ 81.60996755, -43.70853871,   4.26639635],\n",
       "       ...,\n",
       "       [ 92.26904341, 119.09599656, -15.04651118],\n",
       "       [ 91.80678871,  67.78037375,  14.40707256],\n",
       "       [ 91.17355665,  -3.56256085,  31.49238734]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if PCA is needed (typically when >100 features)\n",
    "if X_final.shape[1] > 100:\n",
    "    pca = PCA(n_components=0.95)  # Keep 95% variance\n",
    "    X_pca = pca.fit_transform(X_final)\n",
    "    print(f\"Reduced from {X_final.shape[1]} to {pca.n_components_} features\")\n",
    "else:\n",
    "    X_pca = X_final\n",
    "\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X, y, use_pca=False):\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    metrics = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        if use_pca:\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        metrics.append({\n",
    "            'MAE': mean_absolute_error(y_test, preds),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_test, preds)),\n",
    "            'MAPE': np.mean(np.abs((y_test - preds) / y_test)) * 100\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(metrics).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: week_of_year",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# No PCA needed - LightGBM handles high dimensionality well\u001b[39;00m\n\u001b[0;32m      4\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\n\u001b[0;32m      5\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcat_cols,\n\u001b[0;32m      6\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m lgb_results \u001b[38;5;241m=\u001b[39m evaluate_model(lgb_model, X_final, y)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightGBM Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(lgb_results)\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X, y, use_pca)\u001b[0m\n\u001b[0;32m     13\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m     14\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m---> 16\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m metrics\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_absolute_error(y_test, preds),\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, preds)),\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs((y_test \u001b[38;5;241m-\u001b[39m preds) \u001b[38;5;241m/\u001b[39m y_test)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     23\u001b[0m })\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[0;32m    896\u001b[0m                 eval_set\u001b[38;5;241m=\u001b[39meval_set, eval_names\u001b[38;5;241m=\u001b[39meval_names, eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[0;32m    897\u001b[0m                 eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score, eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m    898\u001b[0m                 early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds, verbose\u001b[38;5;241m=\u001b[39mverbose, feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m    899\u001b[0m                 categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, init_model\u001b[38;5;241m=\u001b[39minit_model)\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m train_set\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[0;32m   1816\u001b[0m                     weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[0;32m   1817\u001b[0m                     init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score, predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   1818\u001b[0m                     silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msilent, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name,\n\u001b[0;32m   1819\u001b[0m                     categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\basic.py:1474\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mpandas_categorical\n\u001b[0;32m   1473\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[1;32m-> 1474\u001b[0m data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m _data_from_pandas(data,\n\u001b[0;32m   1475\u001b[0m                                                                                      feature_name,\n\u001b[0;32m   1476\u001b[0m                                                                                      categorical_feature,\n\u001b[0;32m   1477\u001b[0m                                                                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical)\n\u001b[0;32m   1478\u001b[0m label \u001b[38;5;241m=\u001b[39m _label_from_pandas(label)\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\DM_ENV\\Lib\\site-packages\\lightgbm\\basic.py:594\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_indices:\n\u001b[0;32m    593\u001b[0m     bad_index_cols_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data\u001b[38;5;241m.\u001b[39mcolumns[bad_indices])\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not expect the data types in the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_index_cols_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    597\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: week_of_year"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# No PCA needed - LightGBM handles high dimensionality well\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    categorical_feature=cat_cols,\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "lgb_results = evaluate_model(lgb_model, X_final, y)\n",
    "print(\"LightGBM Results:\")\n",
    "print(lgb_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
